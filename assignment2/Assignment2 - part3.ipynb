{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III\n",
    "\n",
    "Exercise, sentiment over some books from NLPP1e\n",
    "\n",
    "Download the LabMT wordlist. It's available as supplementary material from Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter (Data Set S1). ** Describe briefly how the list was generated **.\n",
    "\n",
    "Following text sources were used:\n",
    "* Twitter\n",
    "* Google Books (English)\n",
    "* music lyrics (1960 to 2007)\n",
    "* New York Times (1987 to 2007) \n",
    "\n",
    "The words in each source were reorder by decreasing frequency of occurrence. Top 5000 words from each source were merged afterwards and so generated a list of 10,222 unique words.\n",
    "\n",
    "For human evaluations of happiness the Amazon's Mechanical Turk was used to obtain ratings for individual words.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the LabMT word list, ** write a function that calculates sentiment ** given a list of tokens (the tokens should be lower case, etc). The function should complain if there are no words with sentiment attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator\n",
    "from __future__ import division\n",
    "\n",
    "filePath = \"Data_Set_S1.txt\"\n",
    "data = pd.read_table(filePath)\n",
    "\n",
    "#creating the token dictionary\n",
    "\n",
    "subData = data[['word','happiness_average']]\n",
    "\n",
    "\n",
    "dictValues = subData.to_dict('list')['happiness_average']\n",
    "dictKey = subData.to_dict('list')['word']\n",
    "\n",
    "tokenDict = dict(zip(dictKey,dictValues)) #creating dictionary with word:happiness_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_average</th>\n",
       "      <th>happiness_standard_deviation</th>\n",
       "      <th>twitter_rank</th>\n",
       "      <th>google_rank</th>\n",
       "      <th>nyt_rank</th>\n",
       "      <th>lyrics_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8425</th>\n",
       "      <td>fucking</td>\n",
       "      <td>8426</td>\n",
       "      <td>4.64</td>\n",
       "      <td>2.926</td>\n",
       "      <td>448</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  happiness_rank  happiness_average  \\\n",
       "8425  fucking            8426               4.64   \n",
       "\n",
       "      happiness_standard_deviation twitter_rank google_rank nyt_rank  \\\n",
       "8425                         2.926          448          --       --   \n",
       "\n",
       "     lyrics_rank  \n",
       "8425         620  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the word with highest deviation (just being curious)\n",
    "values = data['happiness_standard_deviation']\n",
    "max_index, max_value = max(enumerate(values), key=operator.itemgetter(1))\n",
    "data.loc[data['happiness_rank'] == max_index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenDict = {'a': 5, 'b':1}\n",
    "# tokenList = ['a','a','b','c']\n",
    "\n",
    "def calcSentiment(tokenList):\n",
    "    \n",
    "    tokenList = [x.lower() for x in tokenList] #lowercase all the strings\n",
    "    \n",
    "    sentiment = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for token in tokenList:\n",
    "        \n",
    "        #if token is in the list then add the sentiment rank \n",
    "        if token in tokenDict:\n",
    "            sentiment += tokenDict[token]\n",
    "            counter += 1\n",
    "        #else:\n",
    "         #   print 'token \"{}\" has no happiness rank'.format(token)\n",
    "    \n",
    "#     print counter\n",
    "    if counter == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sentiment / counter\n",
    "\n",
    "# calcSentiment(tokenList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a sentiment profile for the novels in NLPP1e chapter 1. The sentiment profile has sentiment on the y-axis and position in the text on the x-axis. Use a moving average to show how the sentiment changes. Create profiles for sliding windows of length 15 words, 50 words, 100 words, 500 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download()\n",
    "# in case of running it in the new enviroment, make sure you have installed two lines above\n",
    "\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare variables\n",
    "windowSizeList = [15,50,100,500]\n",
    "allTextList = [list(text1),list(text2),list(text3),list(text4),list(text5),\n",
    "              list(text6),list(text7),list(text8),list(text9)\n",
    "              ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculates X and Y for a text based on windowSize\n",
    "def getXYFromWindow(windowSize,text_list):\n",
    "    \n",
    "    resultGraph = {}\n",
    "\n",
    "    for i in range(0,int(len(text_list) / windowSize)):\n",
    "        subTextList = [text_list[index] for index in range(i*windowSize, (i * windowSize) + windowSize)] #get the sublist of windowSize\n",
    "        subTextListSeniment = calcSentiment(subTextList) #calculate sentiment for a window\n",
    "        #pair it with the position in the text, which equals => i +windowSize + windowSize/2 \n",
    "        resultGraph[i * windowSize + windowMiddle] = subTextListSeniment\n",
    "\n",
    "    print \"done with windowsize \" + str(windowSize)\n",
    "    \n",
    "    return resultGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-07ef894882b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwindowResults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mwindowSize\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwindowSizeList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mwindowXY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetXYFromWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mwindowResults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindowXY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-107cee9dee74>\u001b[0m in \u001b[0;36mgetXYFromWindow\u001b[1;34m(windowSize, text_list)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresultGraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0msubTextList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#get the sublist of windowSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msubTextListSeniment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcSentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubTextList\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calculate sentiment for a window\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "textResults = {}\n",
    "counter = 1\n",
    "for text in allTextList:\n",
    "    \n",
    "    windowResults = {}\n",
    "    \n",
    "    for windowSize in windowSizeList:\n",
    "        windowXY = getXYFromWindow(text,windowSize)\n",
    "        \n",
    "        windowResults[windowSize] = windowXY\n",
    "        \n",
    "    textResults[\"text\" + str(counter)] = windowResults\n",
    "    \n",
    "    counter += 1\n",
    "        \n",
    "print \"done with results\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the sentiment profiles. Do they show a similar pattern? What is the effect of changing the size of the sliding window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
